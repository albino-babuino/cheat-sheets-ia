{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scikit-learn - Evaluación de Modelos\n",
        "\n",
        "Este notebook cubre las técnicas de evaluación de modelos en scikit-learn: métricas de clasificación, regresión, validación cruzada y ajuste de hiperparámetros.\n",
        "\n",
        "## Importar Módulos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Métricas de Clasificación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos y entrenar modelo\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "# Métricas básicas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Métricas de Clasificación:\")\n",
        "print(f\"Accuracy (Precisión): {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensibilidad): {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\nMatriz de Confusión:\\n{cm}\")\n",
        "\n",
        "# Reporte completo\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Métricas de Regresión\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Cargar datos de regresión\n",
        "X, y = datasets.load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_reg = LinearRegression()\n",
        "model_reg.fit(X_train, y_train)\n",
        "y_pred_reg = model_reg.predict(X_test)\n",
        "\n",
        "# Métricas de regresión\n",
        "mse = mean_squared_error(y_test, y_pred_reg)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_reg)\n",
        "r2 = r2_score(y_test, y_pred_reg)\n",
        "\n",
        "print(\"Métricas de Regresión:\")\n",
        "print(f\"MSE (Mean Squared Error): {mse:.4f}\")\n",
        "print(f\"RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
        "print(f\"MAE (Mean Absolute Error): {mae:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validación Cruzada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validación cruzada simple\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
        "print(\"K-Fold Cross Validation (5 folds):\")\n",
        "print(f\"Scores: {cv_scores}\")\n",
        "print(f\"Media: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "# Stratified K-Fold (mantiene proporción de clases)\n",
        "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores_strat = cross_val_score(model, X, y, cv=skfold, scoring='accuracy')\n",
        "print(f\"\\nStratified K-Fold Cross Validation:\")\n",
        "print(f\"Scores: {cv_scores_strat}\")\n",
        "print(f\"Media: {cv_scores_strat.mean():.4f} (+/- {cv_scores_strat.std() * 2:.4f})\")\n",
        "\n",
        "# Múltiples métricas\n",
        "cv_results = cross_validate(model, X, y, cv=5, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
        "print(f\"\\nMúltiples métricas:\")\n",
        "for metric in cv_results.keys():\n",
        "    if metric.startswith('test_'):\n",
        "        print(f\"  {metric}: {cv_results[metric].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Búsqueda de Hiperparámetros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search (búsqueda exhaustiva)\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir parámetros a buscar\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Grid Search:\")\n",
        "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
        "print(f\"Mejor score (CV): {grid_search.best_score_:.4f}\")\n",
        "print(f\"Score en test: {grid_search.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Randomized Search (búsqueda aleatoria, más eficiente)\n",
        "from scipy.stats import randint\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': randint(2, 20)\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(rf, param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nRandomized Search:\")\n",
        "print(f\"Mejores parámetros: {random_search.best_params_}\")\n",
        "print(f\"Mejor score (CV): {random_search.best_score_:.4f}\")\n",
        "print(f\"Score en test: {random_search.score(X_test, y_test):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Curvas ROC y AUC (Clasificación Binaria)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Para clasificación binaria\n",
        "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_binary = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model_binary.fit(X_train, y_train)\n",
        "y_pred_proba_binary = model_binary.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular ROC curve y AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_binary)\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba_binary)\n",
        "\n",
        "print(f\"AUC Score: {auc_score:.4f}\")\n",
        "print(\"Nota: Para visualizar la curva ROC, usar:\")\n",
        "print(\"  plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\")\n",
        "print(\"  plt.plot([0, 1], [0, 1], 'k--')\")\n",
        "print(\"  plt.xlabel('False Positive Rate')\")\n",
        "print(\"  plt.ylabel('True Positive Rate')\")\n",
        "print(\"  plt.title('ROC Curve')\")\n",
        "print(\"  plt.legend()\")\n",
        "print(\"  plt.show()\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
