{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn - Preprocesamiento de Datos\n",
    "\n",
    "Este notebook cubre las técnicas de preprocesamiento de datos en scikit-learn: escalado, normalización, codificación de variables categóricas y manejo de valores faltantes.\n",
    "\n",
    "## Importar Módulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:13:14.242764Z",
     "iopub.status.busy": "2025-12-07T17:13:14.242613Z",
     "iopub.status.idle": "2025-12-07T17:13:14.920460Z",
     "shell.execute_reply": "2025-12-07T17:13:14.919874Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:13:14.922369Z",
     "iopub.status.busy": "2025-12-07T17:13:14.922186Z",
     "iopub.status.idle": "2025-12-07T17:13:14.928762Z",
     "shell.execute_reply": "2025-12-07T17:13:14.928239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "Media: [0. 0. 0.]\n",
      "Desv. estándar: [1. 1. 1.]\n",
      "\n",
      "MinMaxScaler (rango [0,1]):\n",
      "[[0.  0.  0. ]\n",
      " [0.5 0.5 0.5]\n",
      " [1.  1.  1. ]]\n",
      "\n",
      "RobustScaler:\n",
      "[[-1. -1. -1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 1.  1.  1.]]\n",
      "\n",
      "Normalizer (norma unitaria por fila):\n",
      "[[0.26726124 0.53452248 0.80178373]\n",
      " [0.45584231 0.56980288 0.68376346]\n",
      " [0.50257071 0.57436653 0.64616234]]\n"
     ]
    }
   ],
   "source": [
    "# Datos de ejemplo\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# StandardScaler: estandarización (media=0, desv. estándar=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"StandardScaler:\")\n",
    "print(f\"Media: {X_scaled.mean(axis=0)}\")\n",
    "print(f\"Desv. estándar: {X_scaled.std(axis=0)}\")\n",
    "\n",
    "# MinMaxScaler: normalización a rango [0, 1]\n",
    "minmax = MinMaxScaler()\n",
    "X_minmax = minmax.fit_transform(X)\n",
    "print(\"\\nMinMaxScaler (rango [0,1]):\")\n",
    "print(X_minmax)\n",
    "\n",
    "# RobustScaler: usa mediana y rango intercuartílico (robusto a outliers)\n",
    "robust = RobustScaler()\n",
    "X_robust = robust.fit_transform(X)\n",
    "print(\"\\nRobustScaler:\")\n",
    "print(X_robust)\n",
    "\n",
    "# Normalizer: normaliza cada muestra (fila) a norma unitaria\n",
    "normalizer = Normalizer()\n",
    "X_norm = normalizer.fit_transform(X)\n",
    "print(\"\\nNormalizer (norma unitaria por fila):\")\n",
    "print(X_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificación de Variables Categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:13:14.956491Z",
     "iopub.status.busy": "2025-12-07T17:13:14.956305Z",
     "iopub.status.idle": "2025-12-07T17:13:14.961890Z",
     "shell.execute_reply": "2025-12-07T17:13:14.961367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder:\n",
      "Original: ['rojo', 'verde', 'azul', 'rojo', 'verde']\n",
      "Codificado: [1 2 0 1 2]\n",
      "Clases: ['azul' 'rojo' 'verde']\n",
      "\n",
      "OneHotEncoder:\n",
      "[[1. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0.]]\n",
      "Nombres de características: ['x0_A' 'x0_B' 'x0_C' 'x1_X' 'x1_Y']\n",
      "\n",
      "OrdinalEncoder:\n",
      "[[0. 0.]\n",
      " [1. 1.]\n",
      " [2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# LabelEncoder: codifica etiquetas a números (0, 1, 2, ...)\n",
    "labels = ['rojo', 'verde', 'azul', 'rojo', 'verde']\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "print(\"LabelEncoder:\")\n",
    "print(f\"Original: {labels}\")\n",
    "print(f\"Codificado: {labels_encoded}\")\n",
    "print(f\"Clases: {le.classes_}\")\n",
    "\n",
    "# OneHotEncoder: codificación one-hot (binaria)\n",
    "categories = [['A', 'B', 'C'], ['X', 'Y']]\n",
    "ohe = OneHotEncoder()\n",
    "data_cat = [['A', 'X'], ['B', 'Y'], ['C', 'X']]\n",
    "data_encoded = ohe.fit_transform(data_cat).toarray()\n",
    "print(\"\\nOneHotEncoder:\")\n",
    "print(data_encoded)\n",
    "print(f\"Nombres de características: {ohe.get_feature_names_out()}\")\n",
    "\n",
    "# OrdinalEncoder: codificación ordinal (similar a LabelEncoder pero para múltiples columnas)\n",
    "oe = OrdinalEncoder()\n",
    "data_ordinal = oe.fit_transform(data_cat)\n",
    "print(\"\\nOrdinalEncoder:\")\n",
    "print(data_ordinal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de Valores Faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:13:14.963089Z",
     "iopub.status.busy": "2025-12-07T17:13:14.962966Z",
     "iopub.status.idle": "2025-12-07T17:13:14.967946Z",
     "shell.execute_reply": "2025-12-07T17:13:14.967424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleImputer (media):\n",
      "[[1.  2.  7.5]\n",
      " [4.  5.  6. ]\n",
      " [7.  8.  9. ]]\n",
      "\n",
      "SimpleImputer (mediana):\n",
      "[[1.  2.  7.5]\n",
      " [4.  5.  6. ]\n",
      " [7.  8.  9. ]]\n",
      "\n",
      "SimpleImputer (constante=0):\n",
      "[[1. 2. 0.]\n",
      " [4. 0. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# Datos con valores faltantes\n",
    "X_missing = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9]])\n",
    "\n",
    "# SimpleImputer: imputación de valores faltantes\n",
    "# Estrategias: 'mean', 'median', 'most_frequent', 'constant'\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer_mean.fit_transform(X_missing)\n",
    "print(\"SimpleImputer (media):\")\n",
    "print(X_imputed)\n",
    "\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "X_imputed_median = imputer_median.fit_transform(X_missing)\n",
    "print(\"\\nSimpleImputer (mediana):\")\n",
    "print(X_imputed_median)\n",
    "\n",
    "imputer_constant = SimpleImputer(strategy='constant', fill_value=0)\n",
    "X_imputed_const = imputer_constant.fit_transform(X_missing)\n",
    "print(\"\\nSimpleImputer (constante=0):\")\n",
    "print(X_imputed_const)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones Polinómicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:13:14.969072Z",
     "iopub.status.busy": "2025-12-07T17:13:14.968954Z",
     "iopub.status.idle": "2025-12-07T17:13:14.972915Z",
     "shell.execute_reply": "2025-12-07T17:13:14.972405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolynomialFeatures (grado 2):\n",
      "Original shape: (2, 2)\n",
      "Polinómico shape: (2, 5)\n",
      "[[ 2.  3.  4.  6.  9.]\n",
      " [ 4.  5. 16. 20. 25.]]\n",
      "Nombres: ['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2']\n",
      "\n",
      "Con bias (columna de unos):\n",
      "[[ 1.  2.  3.  4.  6.  9.]\n",
      " [ 1.  4.  5. 16. 20. 25.]]\n"
     ]
    }
   ],
   "source": [
    "# PolynomialFeatures: genera características polinómicas\n",
    "X = np.array([[2, 3], [4, 5]])\n",
    "\n",
    "# Grado 2\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "print(\"PolynomialFeatures (grado 2):\")\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Polinómico shape: {X_poly.shape}\")\n",
    "print(X_poly)\n",
    "print(f\"Nombres: {poly.get_feature_names_out()}\")\n",
    "\n",
    "# Con sesgo (bias)\n",
    "poly_bias = PolynomialFeatures(degree=2, include_bias=True)\n",
    "X_poly_bias = poly_bias.fit_transform(X)\n",
    "print(\"\\nCon bias (columna de unos):\")\n",
    "print(X_poly_bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de Preprocesamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:13:14.974020Z",
     "iopub.status.busy": "2025-12-07T17:13:14.973906Z",
     "iopub.status.idle": "2025-12-07T17:13:14.979577Z",
     "shell.execute_reply": "2025-12-07T17:13:14.979008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline de preprocesamiento:\n",
      "Shape original: (3, 2)\n",
      "Shape procesado: (3, 5)\n",
      "[[-1.22474487 -1.22474487  1.5         1.5         1.5       ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 1.22474487  1.22474487  1.5         1.5         1.5       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Crear un pipeline de preprocesamiento\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "])\n",
    "\n",
    "# Aplicar pipeline\n",
    "X_example = np.array([[1, 2], [3, np.nan], [5, 6]])\n",
    "X_processed = pipeline.fit_transform(X_example)\n",
    "print(\"Pipeline de preprocesamiento:\")\n",
    "print(f\"Shape original: {X_example.shape}\")\n",
    "print(f\"Shape procesado: {X_processed.shape}\")\n",
    "print(X_processed)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
