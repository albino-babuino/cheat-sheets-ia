{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Árboles de Decisión\n",
        "\n",
        "Este notebook explica el algoritmo de Árboles de Decisión, uno de los algoritmos más intuitivos y versátiles en Machine Learning.\n",
        "\n",
        "## ¿Qué es un Árbol de Decisión?\n",
        "\n",
        "Un árbol de decisión es un modelo de aprendizaje supervisado que utiliza una estructura de árbol para tomar decisiones. Cada nodo interno representa una prueba sobre un atributo, cada rama representa el resultado de la prueba, y cada hoja (nodo terminal) representa una clase o valor.\n",
        "\n",
        "## Ventajas y Desventajas\n",
        "\n",
        "**Ventajas:**\n",
        "- Fácil de entender e interpretar\n",
        "- Requiere poca preparación de datos\n",
        "- Puede manejar datos numéricos y categóricos\n",
        "- No requiere normalización de datos\n",
        "\n",
        "**Desventajas:**\n",
        "- Puede sobreajustarse fácilmente (overfitting)\n",
        "- Puede ser inestable (pequeños cambios en datos pueden generar árboles muy diferentes)\n",
        "- Sesgo hacia características con más niveles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Seaborn es opcional, si no está instalado usamos matplotlib\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    HAS_SEABORN = True\n",
        "except ImportError:\n",
        "    HAS_SEABORN = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conceptos Fundamentales\n",
        "\n",
        "### 1. Entropía\n",
        "La entropía mide la impureza o desorden en un conjunto de datos. Se calcula como:\n",
        "\n",
        "$$H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i)$$\n",
        "\n",
        "donde $p_i$ es la proporción de ejemplos de la clase $i$ en el conjunto $S$.\n",
        "\n",
        "### 2. Ganancia de Información\n",
        "La ganancia de información mide la reducción en entropía después de dividir un conjunto según un atributo:\n",
        "\n",
        "$$IG(S, A) = H(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} H(S_v)$$\n",
        "\n",
        "### 3. Índice Gini\n",
        "El índice Gini es otra medida de impureza:\n",
        "\n",
        "$$Gini(S) = 1 - \\sum_{i=1}^{c} p_i^2$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo de cálculo de entropía\n",
        "def entropia(y):\n",
        "    \"\"\"Calcula la entropía de un conjunto de etiquetas\"\"\"\n",
        "    if len(y) == 0:\n",
        "        return 0\n",
        "    # Contar frecuencias de cada clase\n",
        "    counts = np.bincount(y)\n",
        "    # Calcular proporciones\n",
        "    proportions = counts / len(y)\n",
        "    # Eliminar ceros para evitar log(0)\n",
        "    proportions = proportions[proportions > 0]\n",
        "    # Calcular entropía\n",
        "    return -np.sum(proportions * np.log2(proportions))\n",
        "\n",
        "# Ejemplo de cálculo de índice Gini\n",
        "def gini(y):\n",
        "    \"\"\"Calcula el índice Gini de un conjunto de etiquetas\"\"\"\n",
        "    if len(y) == 0:\n",
        "        return 0\n",
        "    counts = np.bincount(y)\n",
        "    proportions = counts / len(y)\n",
        "    return 1 - np.sum(proportions ** 2)\n",
        "\n",
        "# Ejemplo\n",
        "y_ejemplo = np.array([0, 0, 0, 1, 1, 1, 1, 1])\n",
        "print(f\"Entropía: {entropia(y_ejemplo):.4f}\")\n",
        "print(f\"Gini: {gini(y_ejemplo):.4f}\")\n",
        "\n",
        "# Conjunto más puro\n",
        "y_puro = np.array([0, 0, 0, 0, 0, 0])\n",
        "print(f\"\\nConjunto puro - Entropía: {entropia(y_puro):.4f}, Gini: {gini(y_puro):.4f}\")\n",
        "\n",
        "# Conjunto más impuro (50-50)\n",
        "y_impuro = np.array([0, 0, 0, 1, 1, 1])\n",
        "print(f\"Conjunto impuro - Entropía: {entropia(y_impuro):.4f}, Gini: {gini(y_impuro):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Árbol de Decisión para Clasificación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset de iris\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Crear y entrenar el árbol de decisión\n",
        "dt_clf = DecisionTreeClassifier(\n",
        "    criterion='gini',        # Criterio de división: 'gini' o 'entropy'\n",
        "    max_depth=3,             # Profundidad máxima del árbol\n",
        "    min_samples_split=2,     # Mínimo de muestras para dividir un nodo\n",
        "    min_samples_leaf=1,      # Mínimo de muestras en una hoja\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = dt_clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión: {accuracy:.4f}\")\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar el árbol de decisión\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_clf, \n",
        "          feature_names=iris.feature_names,\n",
        "          class_names=iris.target_names,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title(\"Árbol de Decisión - Dataset Iris\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "if HAS_SEABORN:\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=iris.target_names,\n",
        "                yticklabels=iris.target_names)\n",
        "else:\n",
        "    # Usar matplotlib si seaborn no está disponible\n",
        "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(iris.target_names))\n",
        "    plt.xticks(tick_marks, iris.target_names)\n",
        "    plt.yticks(tick_marks, iris.target_names)\n",
        "    # Añadir valores en las celdas\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.ylabel('Clase Real')\n",
        "plt.xlabel('Clase Predicha')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Árbol de Decisión para Regresión\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset de regresión\n",
        "boston = datasets.fetch_california_housing()\n",
        "X_reg, y_reg = boston.data, boston.target\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Crear y entrenar el árbol de decisión para regresión\n",
        "dt_reg = DecisionTreeRegressor(\n",
        "    max_depth=5,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt_reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred_reg = dt_reg.predict(X_test_reg)\n",
        "\n",
        "# Evaluar el modelo\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar predicciones vs valores reales\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_reg, y_pred_reg, alpha=0.5)\n",
        "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
        "         [y_test_reg.min(), y_test_reg.max()], \n",
        "         'r--', lw=2)\n",
        "plt.xlabel('Valores Reales')\n",
        "plt.ylabel('Valores Predichos')\n",
        "plt.title('Árbol de Decisión - Regresión')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importancia de Características\n",
        "\n",
        "Los árboles de decisión pueden mostrar qué características son más importantes para hacer predicciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importancia de características en el árbol de clasificación\n",
        "feature_importance = dt_clf.feature_importances_\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Crear DataFrame para visualización\n",
        "importance_df = pd.DataFrame({\n",
        "    'Característica': feature_names,\n",
        "    'Importancia': feature_importance\n",
        "}).sort_values('Importancia', ascending=False)\n",
        "\n",
        "print(\"Importancia de características:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Visualizar importancia\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df['Característica'], importance_df['Importancia'])\n",
        "plt.xlabel('Importancia')\n",
        "plt.title('Importancia de Características - Árbol de Decisión')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Control de Sobreajuste (Overfitting)\n",
        "\n",
        "El sobreajuste ocurre cuando el árbol se ajusta demasiado a los datos de entrenamiento. Podemos controlarlo con varios parámetros:\n",
        "\n",
        "- **max_depth**: Limita la profundidad máxima del árbol\n",
        "- **min_samples_split**: Mínimo de muestras requeridas para dividir un nodo\n",
        "- **min_samples_leaf**: Mínimo de muestras requeridas en una hoja\n",
        "- **max_features**: Número máximo de características a considerar para dividir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar diferentes profundidades máximas\n",
        "depths = range(1, 11)\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for depth in depths:\n",
        "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    dt.fit(X_train, y_train)\n",
        "    train_scores.append(dt.score(X_train, y_train))\n",
        "    test_scores.append(dt.score(X_test, y_test))\n",
        "\n",
        "# Visualizar resultados\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(depths, train_scores, 'o-', label='Entrenamiento', linewidth=2)\n",
        "plt.plot(depths, test_scores, 's-', label='Prueba', linewidth=2)\n",
        "plt.xlabel('Profundidad Máxima')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Efecto de la Profundidad en el Rendimiento')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"Podemos ver cómo el sobreajuste aumenta con la profundidad\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
