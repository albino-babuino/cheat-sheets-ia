{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Perceptrón\n",
        "\n",
        "Este notebook explica el algoritmo Perceptrón, la unidad básica de las redes neuronales y uno de los primeros algoritmos de aprendizaje automático.\n",
        "\n",
        "## ¿Qué es el Perceptrón?\n",
        "\n",
        "El Perceptrón es un algoritmo de aprendizaje supervisado para clasificación binaria. Es un tipo de neurona artificial que puede aprender a clasificar datos linealmente separables.\n",
        "\n",
        "## Conceptos Fundamentales\n",
        "\n",
        "- **Neurona artificial**: Modelo matemático que simula una neurona biológica\n",
        "- **Pesos (w)**: Parámetros que se aprenden durante el entrenamiento\n",
        "- **Bias (b)**: Término de sesgo que permite ajustar la función de activación\n",
        "- **Función de activación**: Función que determina la salida (step function, sigmoid, etc.)\n",
        "- **Separabilidad lineal**: Los datos deben ser linealmente separables para que el algoritmo converja\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron as SklearnPerceptron\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelo del Perceptrón\n",
        "\n",
        "El Perceptrón calcula:\n",
        "\n",
        "$$z = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b = \\sum_{i=1}^{n} w_i x_i + b$$\n",
        "\n",
        "Y luego aplica una función de activación:\n",
        "\n",
        "$$y = f(z) = \\begin{cases} \n",
        "1 & \\text{si } z \\geq 0 \\\\\n",
        "0 & \\text{si } z < 0\n",
        "\\end{cases}$$\n",
        "\n",
        "Esta es una función de activación escalón (step function).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algoritmo de Aprendizaje\n",
        "\n",
        "El algoritmo de aprendizaje del Perceptrón:\n",
        "\n",
        "1. **Inicializar** pesos y bias aleatoriamente\n",
        "2. **Para cada ejemplo de entrenamiento**:\n",
        "   - Calcular la salida: $y = f(\\sum w_i x_i + b)$\n",
        "   - Si la predicción es incorrecta:\n",
        "     - Actualizar pesos: $w_i = w_i + \\alpha \\times (y_{real} - y_{pred}) \\times x_i$\n",
        "     - Actualizar bias: $b = b + \\alpha \\times (y_{real} - y_{pred})$\n",
        "3. **Repetir** hasta que no haya errores o se alcance el máximo de iteraciones\n",
        "\n",
        "Donde $\\alpha$ es la tasa de aprendizaje.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    \"\"\"Implementación básica del Perceptrón\"\"\"\n",
        "    \n",
        "    def __init__(self, learning_rate=0.01, n_iterations=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Parámetros:\n",
        "        - learning_rate: Tasa de aprendizaje (alpha)\n",
        "        - n_iterations: Número máximo de iteraciones\n",
        "        - random_state: Semilla para reproducibilidad\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.random_state = random_state\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.errors = []\n",
        "    \n",
        "    def activation_function(self, z):\n",
        "        \"\"\"Función de activación escalón\"\"\"\n",
        "        return 1 if z >= 0 else 0\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Entrena el Perceptrón\"\"\"\n",
        "        np.random.seed(self.random_state)\n",
        "        n_samples, n_features = X.shape\n",
        "        \n",
        "        # Inicializar pesos y bias\n",
        "        self.weights = np.random.randn(n_features)\n",
        "        self.bias = 0\n",
        "        \n",
        "        # Convertir etiquetas a 0 y 1 si es necesario\n",
        "        y = np.where(y <= 0, 0, 1)\n",
        "        \n",
        "        for iteration in range(self.n_iterations):\n",
        "            errors_in_iteration = 0\n",
        "            \n",
        "            for i in range(n_samples):\n",
        "                # Calcular salida\n",
        "                z = np.dot(X[i], self.weights) + self.bias\n",
        "                y_pred = self.activation_function(z)\n",
        "                \n",
        "                # Actualizar si hay error\n",
        "                error = y[i] - y_pred\n",
        "                if error != 0:\n",
        "                    self.weights += self.learning_rate * error * X[i]\n",
        "                    self.bias += self.learning_rate * error\n",
        "                    errors_in_iteration += 1\n",
        "            \n",
        "            self.errors.append(errors_in_iteration)\n",
        "            \n",
        "            # Si no hay errores, convergió\n",
        "            if errors_in_iteration == 0:\n",
        "                break\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Hace predicciones\"\"\"\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        return np.array([self.activation_function(val) for val in z])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejemplo: Clasificación Binaria\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar datos linealmente separables\n",
        "X, y = datasets.make_classification(n_samples=100, n_features=2, n_redundant=0,\n",
        "                                    n_informative=2, n_clusters_per_class=1,\n",
        "                                    random_state=42)\n",
        "\n",
        "# Convertir a clasificación binaria (0 y 1)\n",
        "y = np.where(y == 0, 0, 1)\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Usar nuestra implementación\n",
        "perceptron_custom = Perceptron(learning_rate=0.01, n_iterations=1000, random_state=42)\n",
        "perceptron_custom.fit(X_train, y_train)\n",
        "y_pred_custom = perceptron_custom.predict(X_test)\n",
        "\n",
        "# Usar scikit-learn\n",
        "perceptron_sklearn = SklearnPerceptron(max_iter=1000, random_state=42)\n",
        "perceptron_sklearn.fit(X_train, y_train)\n",
        "y_pred_sklearn = perceptron_sklearn.predict(X_test)\n",
        "\n",
        "# Evaluar\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "print(f\"Precisión (Implementación propia): {accuracy_custom:.4f}\")\n",
        "print(f\"Precisión (Scikit-learn): {accuracy_sklearn:.4f}\")\n",
        "print(f\"\\nPesos aprendidos: {perceptron_custom.weights}\")\n",
        "print(f\"Bias aprendido: {perceptron_custom.bias:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar la línea de decisión\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Implementación propia\n",
        "axes[0].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], \n",
        "                c='blue', marker='o', label='Clase 0', alpha=0.6)\n",
        "axes[0].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], \n",
        "                c='red', marker='s', label='Clase 1', alpha=0.6)\n",
        "\n",
        "# Dibujar línea de decisión: w1*x1 + w2*x2 + b = 0\n",
        "# x2 = -(w1*x1 + b) / w2\n",
        "x1_min, x1_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
        "x1_line = np.linspace(x1_min, x1_max, 100)\n",
        "x2_line = -(perceptron_custom.weights[0] * x1_line + perceptron_custom.bias) / perceptron_custom.weights[1]\n",
        "axes[0].plot(x1_line, x2_line, 'k-', linewidth=2, label='Línea de decisión')\n",
        "axes[0].set_xlabel('Característica 1')\n",
        "axes[0].set_ylabel('Característica 2')\n",
        "axes[0].set_title(f'Perceptrón (Implementación Propia) - Precisión: {accuracy_custom:.4f}')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Scikit-learn\n",
        "axes[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], \n",
        "                c='blue', marker='o', label='Clase 0', alpha=0.6)\n",
        "axes[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], \n",
        "                c='red', marker='s', label='Clase 1', alpha=0.6)\n",
        "\n",
        "# Línea de decisión de scikit-learn\n",
        "x2_line_sklearn = -(perceptron_sklearn.coef_[0][0] * x1_line + perceptron_sklearn.intercept_[0]) / perceptron_sklearn.coef_[0][1]\n",
        "axes[1].plot(x1_line, x2_line_sklearn, 'k-', linewidth=2, label='Línea de decisión')\n",
        "axes[1].set_xlabel('Característica 1')\n",
        "axes[1].set_ylabel('Característica 2')\n",
        "axes[1].set_title(f'Perceptrón (Scikit-learn) - Precisión: {accuracy_sklearn:.4f}')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convergencia del Algoritmo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar número de errores por iteración\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(perceptron_custom.errors, 'b-o', linewidth=2, markersize=6)\n",
        "plt.xlabel('Iteración')\n",
        "plt.ylabel('Número de Errores')\n",
        "plt.title('Convergencia del Perceptrón')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Número de iteraciones hasta convergencia: {len(perceptron_custom.errors)}\")\n",
        "print(f\"Total de iteraciones: {perceptron_custom.n_iterations}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limitaciones del Perceptrón Simple\n",
        "\n",
        "El Perceptrón simple solo puede clasificar datos **linealmente separables**. Si los datos no son linealmente separables, el algoritmo nunca convergerá.\n",
        "\n",
        "### Ejemplo: Problema XOR (No linealmente separable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Problema XOR (no linealmente separable)\n",
        "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([0, 1, 1, 0])  # XOR: 0, 1, 1, 0\n",
        "\n",
        "# Intentar entrenar el Perceptrón\n",
        "perceptron_xor = Perceptron(learning_rate=0.1, n_iterations=100, random_state=42)\n",
        "perceptron_xor.fit(X_xor, y_xor)\n",
        "y_pred_xor = perceptron_xor.predict(X_xor)\n",
        "\n",
        "print(\"Problema XOR:\")\n",
        "print(f\"Entradas: {X_xor.tolist()}\")\n",
        "print(f\"Salidas esperadas: {y_xor}\")\n",
        "print(f\"Salidas predichas: {y_pred_xor}\")\n",
        "print(f\"Precisión: {accuracy_score(y_xor, y_pred_xor):.4f}\")\n",
        "print(f\"\\nEl Perceptrón simple NO puede resolver el problema XOR\")\n",
        "print(\"Se necesita una red multicapa (MLP) para problemas no lineales\")\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['blue' if label == 0 else 'red' for label in y_xor]\n",
        "plt.scatter(X_xor[:, 0], X_xor[:, 1], c=colors, s=200, alpha=0.7, edgecolors='black', linewidth=2)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.title('Problema XOR (No Linealmente Separable)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks([0, 1])\n",
        "plt.yticks([0, 1])\n",
        "for i, (x, y) in enumerate(X_xor):\n",
        "    plt.text(x, y, f'({x},{y})', ha='center', va='center', color='white', fontweight='bold')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ventajas y Desventajas\n",
        "\n",
        "**Ventajas:**\n",
        "- Simple de entender e implementar\n",
        "- Rápido de entrenar\n",
        "- Garantiza convergencia si los datos son linealmente separables\n",
        "- Base para redes neuronales más complejas\n",
        "\n",
        "**Desventajas:**\n",
        "- Solo funciona con datos linealmente separables\n",
        "- No puede resolver problemas no lineales (como XOR)\n",
        "- Sensible a la tasa de aprendizaje\n",
        "- Puede no converger si los datos no son separables\n",
        "\n",
        "## Extensión: Perceptrón Multicapa (MLP)\n",
        "\n",
        "Para resolver problemas no lineales, se necesita:\n",
        "- **Múltiples capas** de perceptrones\n",
        "- **Funciones de activación no lineales** (sigmoid, ReLU, tanh)\n",
        "- **Backpropagation** para entrenar\n",
        "\n",
        "## Aplicaciones\n",
        "\n",
        "- Clasificación binaria simple\n",
        "- Base para redes neuronales\n",
        "- Puerta lógica AND/OR\n",
        "- Filtros lineales\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
