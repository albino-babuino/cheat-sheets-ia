{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformers y NLP Moderno\n",
        "\n",
        "Este notebook cubre los conceptos de Transformers y su aplicación en Procesamiento de Lenguaje Natural (NLP).\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Los Transformers son arquitecturas de redes neuronales que han revolucionado el NLP. Introducidos en 2017 con \"Attention Is All You Need\", son la base de modelos como BERT, GPT, T5, etc.\n",
        "\n",
        "### Conceptos Clave\n",
        "\n",
        "- **Attention Mechanism**: Permite al modelo enfocarse en partes relevantes de la entrada\n",
        "- **Self-Attention**: El modelo atiende a diferentes posiciones de su propia secuencia\n",
        "- **Encoder-Decoder**: Arquitectura para tareas de secuencia a secuencia\n",
        "- **Pre-training y Fine-tuning**: Entrenar en grandes corpus y luego adaptar a tareas específicas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importar Librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "    from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "    TRANSFORMERS_AVAILABLE = True\n",
        "    print(\"Transformers disponible\")\n",
        "except ImportError:\n",
        "    TRANSFORMERS_AVAILABLE = False\n",
        "    print(\"Transformers no está instalado. Instala con: pip install transformers torch\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Uso de Modelos Pre-entrenados\n",
        "\n",
        "Hugging Face Transformers proporciona acceso fácil a miles de modelos pre-entrenados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TRANSFORMERS_AVAILABLE:\n",
        "    # Ejemplo 1: Análisis de sentimiento\n",
        "    print(\"=== Análisis de Sentimiento ===\")\n",
        "    classifier = pipeline(\"sentiment-analysis\")\n",
        "    \n",
        "    textos = [\n",
        "        \"Me encanta este producto, es increíble!\",\n",
        "        \"No me gustó para nada, muy decepcionante.\",\n",
        "        \"Está bien, nada especial.\"\n",
        "    ]\n",
        "    \n",
        "    resultados = classifier(textos)\n",
        "    for texto, resultado in zip(textos, resultados):\n",
        "        print(f\"Texto: {texto}\")\n",
        "        print(f\"Sentimiento: {resultado['label']}, Confianza: {resultado['score']:.4f}\\n\")\n",
        "    \n",
        "    # Ejemplo 2: Generación de texto\n",
        "    print(\"\\n=== Generación de Texto ===\")\n",
        "    generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "    \n",
        "    prompt = \"El futuro de la inteligencia artificial\"\n",
        "    generated = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Generado: {generated[0]['generated_text']}\\n\")\n",
        "    \n",
        "    # Ejemplo 3: Traducción\n",
        "    print(\"\\n=== Traducción ===\")\n",
        "    translator = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "    \n",
        "    texto_ingles = \"Hello, how are you today?\"\n",
        "    traduccion = translator(texto_ingles)\n",
        "    print(f\"Original (EN): {texto_ingles}\")\n",
        "    print(f\"Traducción (ES): {traduccion[0]['translation_text']}\\n\")\n",
        "    \n",
        "else:\n",
        "    print(\"Transformers no disponible. Instala con: pip install transformers torch\")\n",
        "    print(\"\\nEjemplos de uso:\")\n",
        "    print(\"1. Análisis de sentimiento: pipeline('sentiment-analysis')\")\n",
        "    print(\"2. Generación de texto: pipeline('text-generation')\")\n",
        "    print(\"3. Traducción: pipeline('translation_en_to_es')\")\n",
        "    print(\"4. Preguntas y respuestas: pipeline('question-answering')\")\n",
        "    print(\"5. Resumen de texto: pipeline('summarization')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Arquitectura Transformer\n",
        "\n",
        "### Componentes Principales\n",
        "\n",
        "1. **Multi-Head Attention**: Múltiples mecanismos de atención en paralelo\n",
        "2. **Position Encoding**: Codifica la posición de las palabras\n",
        "3. **Feed Forward Networks**: Redes completamente conectadas\n",
        "4. **Layer Normalization**: Normalización de capas\n",
        "5. **Residual Connections**: Conexiones residuales para facilitar el entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualización conceptual de la arquitectura Transformer\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 12))\n",
        "\n",
        "# Encoder Stack\n",
        "ax.text(0.5, 0.95, \"TRANSFORMER ENCODER\", ha='center', fontsize=14, fontweight='bold')\n",
        "ax.add_patch(plt.Rectangle((0.1, 0.85), 0.8, 0.08, fill=False, edgecolor='black', linewidth=2))\n",
        "ax.text(0.5, 0.89, \"Multi-Head Attention\", ha='center', fontsize=10)\n",
        "ax.text(0.5, 0.86, \"Add & Norm\", ha='center', fontsize=8)\n",
        "\n",
        "ax.add_patch(plt.Rectangle((0.1, 0.75), 0.8, 0.08, fill=False, edgecolor='black', linewidth=2))\n",
        "ax.text(0.5, 0.79, \"Feed Forward\", ha='center', fontsize=10)\n",
        "ax.text(0.5, 0.76, \"Add & Norm\", ha='center', fontsize=8)\n",
        "\n",
        "# Input Embeddings\n",
        "ax.add_patch(plt.Rectangle((0.1, 0.65), 0.8, 0.08, fill=True, facecolor='lightblue', edgecolor='black'))\n",
        "ax.text(0.5, 0.69, \"Input Embeddings\", ha='center', fontsize=10)\n",
        "ax.text(0.5, 0.66, \"+ Positional Encoding\", ha='center', fontsize=8)\n",
        "\n",
        "# Decoder Stack\n",
        "ax.text(0.5, 0.55, \"TRANSFORMER DECODER\", ha='center', fontsize=14, fontweight='bold')\n",
        "ax.add_patch(plt.Rectangle((0.1, 0.45), 0.8, 0.08, fill=False, edgecolor='black', linewidth=2))\n",
        "ax.text(0.5, 0.49, \"Masked Multi-Head Attention\", ha='center', fontsize=10)\n",
        "ax.text(0.5, 0.46, \"Add & Norm\", ha='center', fontsize=8)\n",
        "\n",
        "ax.add_patch(plt.Rectangle((0.1, 0.35), 0.8, 0.08, fill=False, edgecolor='black', linewidth=2))\n",
        "ax.text(0.5, 0.39, \"Multi-Head Attention\", ha='center', fontsize=10)\n",
        "ax.text(0.5, 0.36, \"Add & Norm\", ha='center', fontsize=8)\n",
        "\n",
        "ax.add_patch(plt.Rectangle((0.1, 0.25), 0.8, 0.08, fill=False, edgecolor='black', linewidth=2))\n",
        "ax.text(0.5, 0.29, \"Feed Forward\", ha='center', fontsize=10)\n",
        "ax.text(0.5, 0.26, \"Add & Norm\", ha='center', fontsize=8)\n",
        "\n",
        "# Output\n",
        "ax.add_patch(plt.Rectangle((0.1, 0.15), 0.8, 0.08, fill=True, facecolor='lightgreen', edgecolor='black'))\n",
        "ax.text(0.5, 0.19, \"Output Probabilities\", ha='center', fontsize=10)\n",
        "ax.text(0.5, 0.16, \"Linear + Softmax\", ha='center', fontsize=8)\n",
        "\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.axis('off')\n",
        "ax.set_title('Arquitectura Transformer', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Componentes clave de un Transformer:\")\n",
        "print(\"1. Attention: Permite al modelo enfocarse en partes relevantes\")\n",
        "print(\"2. Position Encoding: Codifica información posicional\")\n",
        "print(\"3. Feed Forward: Procesa la información\")\n",
        "print(\"4. Layer Norm: Estabiliza el entrenamiento\")\n",
        "print(\"5. Residual Connections: Facilita el flujo de gradientes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Modelos Populares\n",
        "\n",
        "### Modelos Encoder (BERT, RoBERTa)\n",
        "\n",
        "- **BERT**: Bidirectional Encoder Representations from Transformers\n",
        "- **RoBERTa**: Versión optimizada de BERT\n",
        "- **DistilBERT**: Versión más ligera de BERT\n",
        "\n",
        "### Modelos Decoder (GPT)\n",
        "\n",
        "- **GPT-2/GPT-3**: Generative Pre-trained Transformer\n",
        "- **GPT-4**: Versión más avanzada\n",
        "\n",
        "### Modelos Encoder-Decoder (T5, BART)\n",
        "\n",
        "- **T5**: Text-to-Text Transfer Transformer\n",
        "- **BART**: Bidirectional and Auto-Regressive Transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Modelos Transformer Populares:\\n\")\n",
        "\n",
        "modelos = {\n",
        "    \"Encoder\": [\"BERT\", \"RoBERTa\", \"DistilBERT\", \"ELECTRA\"],\n",
        "    \"Decoder\": [\"GPT-2\", \"GPT-3\", \"GPT-4\", \"LLaMA\"],\n",
        "    \"Encoder-Decoder\": [\"T5\", \"BART\", \"mT5\", \"UL2\"]\n",
        "}\n",
        "\n",
        "for tipo, lista_modelos in modelos.items():\n",
        "    print(f\"{tipo}:\")\n",
        "    for modelo in lista_modelos:\n",
        "        print(f\"  - {modelo}\")\n",
        "    print()\n",
        "\n",
        "print(\"Aplicaciones:\")\n",
        "print(\"- Clasificación de texto\")\n",
        "print(\"- Análisis de sentimiento\")\n",
        "print(\"- Traducción automática\")\n",
        "print(\"- Generación de texto\")\n",
        "print(\"- Preguntas y respuestas\")\n",
        "print(\"- Resumen de texto\")\n",
        "print(\"- Named Entity Recognition (NER)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
