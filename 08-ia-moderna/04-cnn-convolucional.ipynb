{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Redes Neuronales Convolucionales (CNN)\n",
        "\n",
        "Este notebook cubre las Redes Neuronales Convolucionales (CNN), fundamentales para el procesamiento de imágenes y visión por computadora.\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Las CNN son un tipo especial de red neuronal diseñada para procesar datos con estructura de cuadrícula, como imágenes. Utilizan operaciones de convolución para detectar características locales.\n",
        "\n",
        "### Conceptos Clave\n",
        "\n",
        "- **Convolución**: Operación que aplica filtros (kernels) para detectar características\n",
        "- **Pooling**: Reducción de dimensionalidad preservando información importante\n",
        "- **Feature Maps**: Mapas de características extraídas por las capas convolucionales\n",
        "- **Padding**: Añadir píxeles alrededor de la imagen para controlar el tamaño de salida\n",
        "- **Stride**: Paso de desplazamiento del kernel durante la convolución\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importar Librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Intentar importar TensorFlow/Keras\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers, models\n",
        "    from tensorflow.keras.datasets import mnist, cifar10\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    TENSORFLOW_AVAILABLE = True\n",
        "    print(f\"TensorFlow versión: {tf.__version__}\")\n",
        "except ImportError:\n",
        "    TENSORFLOW_AVAILABLE = False\n",
        "    print(\"TensorFlow no está instalado. Instala con: pip install tensorflow\")\n",
        "\n",
        "np.random.seed(42)\n",
        "if TENSORFLOW_AVAILABLE:\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "# Configuración de visualización\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except:\n",
        "    plt.style.use('seaborn')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Operación de Convolución desde Cero\n",
        "\n",
        "Implementemos la operación de convolución básica para entender cómo funciona.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convolve2d(image, kernel, padding=0, stride=1):\n",
        "    \"\"\"\n",
        "    Aplica convolución 2D a una imagen\n",
        "    \n",
        "    Parameters:\n",
        "    - image: array 2D (alto, ancho)\n",
        "    - kernel: array 2D (alto_kernel, ancho_kernel)\n",
        "    - padding: número de píxeles a añadir alrededor\n",
        "    - stride: paso de desplazamiento\n",
        "    \"\"\"\n",
        "    # Añadir padding\n",
        "    if padding > 0:\n",
        "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
        "    \n",
        "    # Dimensiones\n",
        "    img_h, img_w = image.shape\n",
        "    kernel_h, kernel_w = kernel.shape\n",
        "    \n",
        "    # Calcular dimensiones de salida\n",
        "    out_h = (img_h - kernel_h) // stride + 1\n",
        "    out_w = (img_w - kernel_w) // stride + 1\n",
        "    \n",
        "    # Inicializar output\n",
        "    output = np.zeros((out_h, out_w))\n",
        "    \n",
        "    # Aplicar convolución\n",
        "    for i in range(0, out_h):\n",
        "        for j in range(0, out_w):\n",
        "            # Extraer región\n",
        "            region = image[i*stride:i*stride+kernel_h, j*stride:j*stride+kernel_w]\n",
        "            # Multiplicar elemento por elemento y sumar\n",
        "            output[i, j] = np.sum(region * kernel)\n",
        "    \n",
        "    return output\n",
        "\n",
        "# Ejemplo: Crear imagen simple\n",
        "image = np.array([\n",
        "    [1, 1, 1, 0, 0],\n",
        "    [0, 1, 1, 1, 0],\n",
        "    [0, 0, 1, 1, 1],\n",
        "    [0, 0, 1, 1, 0],\n",
        "    [0, 1, 1, 0, 0]\n",
        "])\n",
        "\n",
        "# Kernel de detección de bordes verticales\n",
        "kernel_vertical = np.array([\n",
        "    [-1, 0, 1],\n",
        "    [-1, 0, 1],\n",
        "    [-1, 0, 1]\n",
        "])\n",
        "\n",
        "# Kernel de detección de bordes horizontales\n",
        "kernel_horizontal = np.array([\n",
        "    [-1, -1, -1],\n",
        "    [0, 0, 0],\n",
        "    [1, 1, 1]\n",
        "])\n",
        "\n",
        "# Aplicar convolución\n",
        "output_vertical = convolve2d(image, kernel_vertical, padding=1, stride=1)\n",
        "output_horizontal = convolve2d(image, kernel_horizontal, padding=1, stride=1)\n",
        "\n",
        "# Visualización\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(image, cmap='gray')\n",
        "axes[0].set_title('Imagen Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(output_vertical, cmap='gray')\n",
        "axes[1].set_title('Detección de Bordes Verticales')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(output_horizontal, cmap='gray')\n",
        "axes[2].set_title('Detección de Bordes Horizontales')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Operación de convolución completada\")\n",
        "print(f\"Tamaño imagen original: {image.shape}\")\n",
        "print(f\"Tamaño kernel: {kernel_vertical.shape}\")\n",
        "print(f\"Tamaño salida (con padding=1): {output_vertical.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Pooling (Max Pooling y Average Pooling)\n",
        "\n",
        "El pooling reduce la dimensionalidad y ayuda a hacer el modelo más robusto a pequeñas traslaciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def max_pooling(image, pool_size=2, stride=2):\n",
        "    \"\"\"Max Pooling: toma el valor máximo en cada región\"\"\"\n",
        "    h, w = image.shape\n",
        "    out_h = (h - pool_size) // stride + 1\n",
        "    out_w = (w - pool_size) // stride + 1\n",
        "    \n",
        "    output = np.zeros((out_h, out_w))\n",
        "    \n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            region = image[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size]\n",
        "            output[i, j] = np.max(region)\n",
        "    \n",
        "    return output\n",
        "\n",
        "def average_pooling(image, pool_size=2, stride=2):\n",
        "    \"\"\"Average Pooling: toma el promedio en cada región\"\"\"\n",
        "    h, w = image.shape\n",
        "    out_h = (h - pool_size) // stride + 1\n",
        "    out_w = (w - pool_size) // stride + 1\n",
        "    \n",
        "    output = np.zeros((out_h, out_w))\n",
        "    \n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            region = image[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size]\n",
        "            output[i, j] = np.mean(region)\n",
        "    \n",
        "    return output\n",
        "\n",
        "# Crear imagen de ejemplo más grande\n",
        "image = np.random.rand(8, 8) * 255\n",
        "\n",
        "# Aplicar pooling\n",
        "max_pooled = max_pooling(image, pool_size=2, stride=2)\n",
        "avg_pooled = average_pooling(image, pool_size=2, stride=2)\n",
        "\n",
        "# Visualización\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(image, cmap='viridis')\n",
        "axes[0].set_title('Imagen Original (8x8)')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(max_pooled, cmap='viridis')\n",
        "axes[1].set_title('Max Pooling (4x4)')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(avg_pooled, cmap='viridis')\n",
        "axes[2].set_title('Average Pooling (4x4)')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Tamaño original: {image.shape}\")\n",
        "print(f\"Tamaño después de pooling: {max_pooled.shape}\")\n",
        "print(f\"Reducción: {image.size / max_pooled.size:.1f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CNN con TensorFlow/Keras\n",
        "\n",
        "Si TensorFlow está disponible, construiremos una CNN completa para clasificación de imágenes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TENSORFLOW_AVAILABLE:\n",
        "    # Cargar datos MNIST\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    \n",
        "    # Preprocesar datos\n",
        "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "    \n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "    \n",
        "    # Construir modelo CNN\n",
        "    model = models.Sequential([\n",
        "        # Primera capa convolucional\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        # Segunda capa convolucional\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        # Tercera capa convolucional\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        \n",
        "        # Aplanar y capas densas\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    # Compilar modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Resumen del modelo\n",
        "    print(\"Arquitectura del modelo CNN:\")\n",
        "    model.summary()\n",
        "    \n",
        "    # Entrenar modelo (solo unas pocas épocas para demostración)\n",
        "    print(\"\\nEntrenando modelo (esto puede tardar unos minutos)...\")\n",
        "    history = model.fit(X_train, y_train, \n",
        "                       epochs=3, \n",
        "                       batch_size=128,\n",
        "                       validation_split=0.1,\n",
        "                       verbose=1)\n",
        "    \n",
        "    # Evaluar\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\nPrecisión en test: {test_acc:.4f}\")\n",
        "    \n",
        "    # Visualizar algunas predicciones\n",
        "    predictions = model.predict(X_test[:10])\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "    true_labels = np.argmax(y_test[:10], axis=1)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    for i in range(10):\n",
        "        row = i // 5\n",
        "        col = i % 5\n",
        "        axes[row, col].imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
        "        axes[row, col].set_title(f'Pred: {predicted_labels[i]}, Real: {true_labels[i]}')\n",
        "        axes[row, col].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Visualizar curva de aprendizaje\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    axes[0].plot(history.history['loss'], label='Entrenamiento')\n",
        "    axes[0].plot(history.history['val_loss'], label='Validación')\n",
        "    axes[0].set_xlabel('Época')\n",
        "    axes[0].set_ylabel('Pérdida')\n",
        "    axes[0].set_title('Curva de Pérdida')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    axes[1].plot(history.history['accuracy'], label='Entrenamiento')\n",
        "    axes[1].plot(history.history['val_accuracy'], label='Validación')\n",
        "    axes[1].set_xlabel('Época')\n",
        "    axes[1].set_ylabel('Precisión')\n",
        "    axes[1].set_title('Curva de Precisión')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"TensorFlow no está disponible. Instala con: pip install tensorflow\")\n",
        "    print(\"\\nEjemplo de arquitectura CNN típica:\")\n",
        "    print(\"\"\"\n",
        "    Input (28x28x1)\n",
        "        ↓\n",
        "    Conv2D (32 filtros, 3x3) + ReLU\n",
        "        ↓\n",
        "    MaxPooling2D (2x2)\n",
        "        ↓\n",
        "    Conv2D (64 filtros, 3x3) + ReLU\n",
        "        ↓\n",
        "    MaxPooling2D (2x2)\n",
        "        ↓\n",
        "    Conv2D (64 filtros, 3x3) + ReLU\n",
        "        ↓\n",
        "    Flatten\n",
        "        ↓\n",
        "    Dense (64 neuronas) + ReLU\n",
        "        ↓\n",
        "    Dense (10 neuronas) + Softmax\n",
        "        ↓\n",
        "    Output (10 clases)\n",
        "    \"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Resumen\n",
        "\n",
        "### Componentes de una CNN\n",
        "\n",
        "1. **Capa Convolucional**: Detecta características locales usando filtros\n",
        "2. **Capa de Pooling**: Reduce dimensionalidad y previene sobreajuste\n",
        "3. **Capa de Activación**: Introduce no-linealidad (ReLU, sigmoide, etc.)\n",
        "4. **Capa Flatten**: Convierte mapas 2D en vectores 1D\n",
        "5. **Capa Densa**: Clasificación final\n",
        "\n",
        "### Ventajas de las CNN\n",
        "\n",
        "- **Invariante a traslación**: Detectan características independientemente de su posición\n",
        "- **Eficiencia**: Comparten parámetros (pesos del kernel)\n",
        "- **Jerarquía**: Aprenden características de bajo a alto nivel\n",
        "- **Robustez**: Menos parámetros que redes completamente conectadas\n",
        "\n",
        "### Aplicaciones\n",
        "\n",
        "- Clasificación de imágenes\n",
        "- Detección de objetos\n",
        "- Segmentación semántica\n",
        "- Reconocimiento facial\n",
        "- Procesamiento de video\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
